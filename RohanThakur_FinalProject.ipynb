{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction**\n",
    "\n",
    "This notebook deals with classification of satellite images of roofs into four categories, based on orientation of the roofs.\n",
    "1. North-South Orientation\n",
    "2. East-West Orientation\n",
    "3. Flat Roof\n",
    "4. Other\n",
    "\n",
    "The problem was part of Phase 1 of the [Data Science Games Competition][1], held from June 17 to July 10, in which I participated in a team of 4, along with Sue Yang, Sasanka Gandavarapu, and Jim Chen (all students in MIDS Berkeley).\n",
    "[1]: https://inclass.kaggle.com/c/data-science-game-2016-online-selection\n",
    "\n",
    "This notebook includes mostly final used methods. A separate notebook with unused scratch work and methods is available on request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------\n",
    "Below are the necessary package imports and data processing functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.filters import gaussian\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two different feature sets with which I will be working. \n",
    "\n",
    "*First, the raw pixel matrix. \n",
    "*Second, a feature set consisting of the height-to-width ratio of the image, and a color histogram. \n",
    "\n",
    "All load methods (except for the test set) add the image itself + 3 rotations of the image to the feature set (90, 180, and 270 degree rotations). Methods described below:\n",
    "\n",
    "1. extract_color_histogram: Given an image, returns a feature vector of length 512 representing the color distribution of the image.\n",
    "2. load_unlabelled_pixels: Given a list of image IDs, create a numpy (flattened) pixel matrix for each. Used on unlabelled images.\n",
    "3. load_unlabelled_colors: Given a list of image IDs, create a numpy color historgram feature vector for each. Used on unlabelled images.\n",
    "4. load_train_cv: Returns a train and test set of pixel matrices from the list of labelled examples in id_train.csv. \n",
    "5. load_train_features: Returns a train and test set of color histograms feature vectors from a list of labelled examples in id_train.csv.\n",
    "6. load_test: Returns the pixel matrices feature array corresponding to the test set for the competition, given in sample_submission4.csv\n",
    "7. load_test_hist: Returns the color histogram feature array corresponding to the test set for the competition, given in sample_submission4.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Loading data functions\n",
    "'''\n",
    "PIXELS = 32\n",
    "imageSize = PIXELS * PIXELS\n",
    "num_features = imageSize \n",
    "\n",
    "def extract_color_histogram(image, bins=(8, 8, 8)):\n",
    "    # extract a 3D color histogram from the HSV color space using\n",
    "    # the supplied number of `bins` per channel\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv], [0, 1, 2], None, bins,\n",
    "        [0, 180, 0, 256, 0, 256])\n",
    "\n",
    "    cv2.normalize(hist, hist)\n",
    "\n",
    "    # return the flattened histogram as the feature vector\n",
    "    return hist.flatten()\n",
    "\n",
    "def load_unlabelled_pixels(list_nums):\n",
    "    X = []\n",
    "    for num in list_nums:\n",
    "        file_name = os.path.join('input', str(num) + '.jpg')\n",
    "        img = cv2.imread(file_name,0)\n",
    "        img = cv2.resize(img, (PIXELS, PIXELS))\n",
    "        M = cv2.getRotationMatrix2D((PIXELS/2, PIXELS/2),90,1)\n",
    "        img90 = cv2.warpAffine(img, M, (PIXELS, PIXELS))\n",
    "        img180 = cv2.warpAffine(img90, M, (PIXELS, PIXELS))\n",
    "        img270 = cv2.warpAffine(img180, M, (PIXELS, PIXELS))\n",
    "        img = np.reshape(img, (1, num_features))\n",
    "        img90 = np.reshape(img90, (1, num_features))\n",
    "        img180 = np.reshape(img180, (1, num_features))\n",
    "        img270 = np.reshape(img270, (1, num_features))\n",
    "        X.append(img)\n",
    "        X.append(img90)\n",
    "        X.append(img180)\n",
    "        X.append(img270)\n",
    "    \n",
    "    X = np.array(X)\n",
    "    X = X.reshape(X.shape[0], num_features).astype('float32') / 255\n",
    "    return X\n",
    "\n",
    "def load_unlabelled_colors(list_nums):\n",
    "    X = []\n",
    "    for num in list_nums:\n",
    "        features = []\n",
    "        features90 = []\n",
    "        features180 = []\n",
    "        features270 = []\n",
    "        file_name = os.path.join('input', str(num) + '.jpg')\n",
    "        img = cv2.imread(file_name)\n",
    "        h, w, blah = img.shape\n",
    "        ratio = h/float(w)\n",
    "            \n",
    "        M = cv2.getRotationMatrix2D((w/2, h/2),90,1)\n",
    "        img90 = cv2.warpAffine(img, M, (w, h))\n",
    "        img180 = cv2.warpAffine(img90, M, (w, h))\n",
    "        img270 = cv2.warpAffine(img180, M, (w, h))\n",
    "        \n",
    "        features.extend(extract_color_histogram(img))\n",
    "        features.append(ratio)\n",
    "        features90.extend(extract_color_histogram(img90))\n",
    "        features90.append(1.0/ratio)\n",
    "        features180.extend(extract_color_histogram(img180))\n",
    "        features180.append(ratio)\n",
    "        features270.extend(extract_color_histogram(img270))\n",
    "        features270.append(1.0/ratio)\n",
    "            \n",
    "        X.append(np.array(features))\n",
    "        X.append(np.array(features90))\n",
    "        X.append(np.array(features180))\n",
    "        X.append(np.array(features270))\n",
    "    \n",
    "    X = np.array(X)\n",
    "    return X\n",
    "\n",
    "def load_train_cv(encoder):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    print('Read train images')\n",
    "    #Read train ids\n",
    "    \n",
    "    with open('id_train.csv', 'rb') as csvfile:\n",
    "        trainreader = csv.reader(csvfile, delimiter=',')\n",
    "        next(trainreader)\n",
    "        for row in trainreader:\n",
    "            #print(row[0])\n",
    "            file_name = os.path.join('input', row[0] + '.jpg')\n",
    "            f_nums.remove(int(row[0]))\n",
    "            img = cv2.imread(file_name,0)\n",
    "            \n",
    "            img = cv2.resize(img, (PIXELS, PIXELS))\n",
    "            M = cv2.getRotationMatrix2D((PIXELS/2, PIXELS/2),90,1)\n",
    "            img90 = cv2.warpAffine(img, M, (PIXELS, PIXELS))\n",
    "            img180 = cv2.warpAffine(img90, M, (PIXELS, PIXELS))\n",
    "            img270 = cv2.warpAffine(img180, M, (PIXELS, PIXELS))\n",
    "            img = np.reshape(img, (1, num_features))\n",
    "            img90 = np.reshape(img90, (1, num_features))\n",
    "            img180 = np.reshape(img180, (1, num_features))\n",
    "            img270 = np.reshape(img270, (1, num_features))\n",
    "            X_train.append(img)\n",
    "            X_train.append(img90)\n",
    "            X_train.append(img180)\n",
    "            X_train.append(img270)\n",
    "            y_train.append(row[1])\n",
    "            y_train.append(row[1])\n",
    "            if row[1] == '1':\n",
    "                y_train.append ('2')\n",
    "                y_train.append ('2')\n",
    "            elif row[1] == '2':\n",
    "                y_train.append ('1')\n",
    "                y_train.append ('1')\n",
    "            else:\n",
    "                y_train.append(row[1])\n",
    "                y_train.append(row[1])\n",
    "                \n",
    "    #print X_train.shape\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train).astype('int32')\n",
    "\n",
    "    #y_train = encoder.fit_transform(y_train).astype('int32')\n",
    "\n",
    "    X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.3,random_state=42)\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], num_features).astype('float32') / 255.\n",
    "    X_test = X_test.reshape(X_test.shape[0], num_features).astype('float32') / 255.\n",
    "    #X_train = X_train.astype('float32') / 255.\n",
    "    #X_test = X_test.astype('float32') / 255.\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, encoder\n",
    "\n",
    "def load_train_features(encoder):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    print('Read train images')\n",
    "    #Read train ids\n",
    "    \n",
    "    with open('id_train.csv', 'rb') as csvfile:\n",
    "        trainreader = csv.reader(csvfile, delimiter=',')\n",
    "        next(trainreader)\n",
    "        for row in trainreader:\n",
    "            #print(row[0])\n",
    "            features = []\n",
    "            features90 = []\n",
    "            features180 = []\n",
    "            features270 = []\n",
    "            file_name = os.path.join('input', row[0] + '.jpg')\n",
    "            img = cv2.imread(file_name)\n",
    "            h, w, blah = img.shape\n",
    "            ratio = h/float(w)\n",
    "            \n",
    "            M = cv2.getRotationMatrix2D((w/2, h/2),90,1)\n",
    "            img90 = cv2.warpAffine(img, M, (w, h))\n",
    "            img180 = cv2.warpAffine(img90, M, (w, h))\n",
    "            img270 = cv2.warpAffine(img180, M, (w, h))\n",
    "            \n",
    "            features.extend(extract_color_histogram(img))\n",
    "            features.append(ratio)\n",
    "            features90.extend(extract_color_histogram(img90))\n",
    "            features90.append(1.0/ratio)\n",
    "            features180.extend(extract_color_histogram(img180))\n",
    "            features180.append(ratio)\n",
    "            features270.extend(extract_color_histogram(img270))\n",
    "            features270.append(1.0/ratio)\n",
    "            \n",
    "            X_train.append(np.array(features))\n",
    "            X_train.append(np.array(features90))\n",
    "            X_train.append(np.array(features180))\n",
    "            X_train.append(np.array(features270))\n",
    "            y_train.append(row[1])\n",
    "            y_train.append(row[1])\n",
    "            if row[1] == '1':\n",
    "                y_train.append ('2')\n",
    "                y_train.append ('2')\n",
    "            elif row[1] == '2':\n",
    "                y_train.append ('1')\n",
    "                y_train.append ('1')\n",
    "            else:\n",
    "                y_train.append(row[1])\n",
    "                y_train.append(row[1])\n",
    "                \n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train).astype('int32')\n",
    "\n",
    "    X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, encoder\n",
    "\n",
    "def load_test():\n",
    "    print('Read test images')\n",
    "    X_test = []\n",
    "    X_test_id=[]\n",
    "    with open('sample_submission4.csv', 'rb') as csvfile:\n",
    "        testreader = csv.reader(csvfile, delimiter=',')\n",
    "        next(testreader)\n",
    "        for row in testreader:\n",
    "            #print('Load folder c{}'.format(j))\n",
    "            file_name = os.path.join('input', row[0] + '.jpg')\n",
    "            f_nums.remove(int(row[0]))\n",
    "            img = cv2.imread(file_name,0)\n",
    "            img = cv2.resize(img, (PIXELS, PIXELS))\n",
    "            #img = img.transpose(2, 0, 1)\n",
    "            img = np.reshape(img, (1, num_features))\n",
    "            X_test.append(img)\n",
    "            X_test_id.append(row[0])\n",
    "\n",
    "    X_test = np.array(X_test)\n",
    "    X_test_id = np.array(X_test_id)\n",
    "\n",
    "    X_test = X_test.reshape(X_test.shape[0],num_features ).astype('float32') / 255.\n",
    "\n",
    "    return X_test, X_test_id\n",
    "\n",
    "def load_test_hist():\n",
    "    print('Read test images')\n",
    "    X_test = []\n",
    "    X_test_id=[]\n",
    "    with open('sample_submission4.csv', 'rb') as csvfile:\n",
    "        testreader = csv.reader(csvfile, delimiter=',')\n",
    "        next(testreader)\n",
    "        for row in testreader:\n",
    "            #print('Load folder c{}'.format(j))\n",
    "            features = []\n",
    "            file_name = os.path.join('input', row[0] + '.jpg')\n",
    "            img = cv2.imread(file_name)\n",
    "            h, w, blah = img.shape\n",
    "            ratio = h/float(w)\n",
    "            features.extend(extract_color_histogram(img))\n",
    "            features.append(ratio)\n",
    "            X_test.append(np.array(features))\n",
    "            X_test_id.append(row[0])\n",
    "    X_test = np.array(X_test)\n",
    "    X_test_id = np.array(X_test_id)\n",
    "    return X_test, X_test_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read train images\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "load training data, test, and unlabelled data. Cell takes ~3-5 mins to run\n",
    "'''\n",
    "#Creating list of file IDs (so we can eliminate the labelled and test examples to get the list of unlabelled examples)\n",
    "f_nums = []\n",
    "for root, dirnames, filenames in os.walk('input'):\n",
    "    for f in filenames:\n",
    "        f_nums.append(int(f[:-4]))    \n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# load the training and validation data sets for first feature set\n",
    "train_X, train_y, valid_X, valid_y, encoder = load_train_cv(encoder)\n",
    "\n",
    "# load the training and validation data sets for second feature set\n",
    "train_hist_X, train_hist_y, valid_hist_X, valid_hist_y, encoder = load_train_features(encoder)\n",
    "\n",
    "print \"Dimensions of training and label set for feature set 1: Raw Pixels\"\n",
    "print('Train set shape:', train_X.shape, 'Dev (valid) set shape:', valid_X.shape, valid_X.dtype)\n",
    "print('Train labels shape:', train_y.shape, 'Dev (valid) labels shape:', valid_y.shape)\n",
    "\n",
    "print \"Dimensions of training and label set for feature set 1: Raw Pixels\"\n",
    "print('Train set shape:', train_hist_X.shape, 'Dev (valid) set shape:', valid_hist_X.shape, valid_hist_X.dtype)\n",
    "print('Train labels shape:', train_hist_y.shape, 'Dev (valid) labels shape:', valid_hist_y.shape)\n",
    "\n",
    "# loading test data\n",
    "X_test, X_test_id = load_test()\n",
    "X_test_hist, X_test_id_hist = load_test_hist()\n",
    "print('Test shape:', X_test.shape, ' Test hist shape: ', X_test_hist.shape)\n",
    "\n",
    "print 'Making sure test sets for both feature sets are in the same order:'\n",
    "check = 'All good'\n",
    "for a, b in zip(X_test_id, X_test_id_hist):\n",
    "    if a != b:\n",
    "        check = 'Not equal'\n",
    "print check\n",
    "\n",
    "print 'Loading unlabelled data:'\n",
    "X_unlabelled_pixels = load_unlabelled_pixels(f_nums)\n",
    "X_unlabelled_colors = load_unlabelled_colors(f_nums)\n",
    "print('X_unlabelled_pixels shape:', X_unlabelled_pixels.shape, 'X_unlabelled_colors shape:', X_unlabelled_colors.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After experimenting with various models (KNN, NB, DecisionTrees, GradientBoostedTrees, AdaBoost etc.), Random Forest performed the best. Below, we find the best parameters for the Random Forest models on both feature vector sets. The 2 cells below take 50-60 mins each to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter set:  {'n_estimators': 200, 'bootstrap': False, 'class_weight': 'balanced'}\n",
      "Best score:  0.564953920884\n"
     ]
    }
   ],
   "source": [
    "# Pick n_estimators=80\n",
    "#Lets tune for max_depth and min_samples_split\n",
    "param_test = {'n_estimators':range(50,201,50), 'bootstrap':[True, False], \n",
    "              'class_weight':['balanced', 'balanced_subsample', None] }\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "gsearch2 = GridSearchCV(estimator = clf, param_grid = param_test, n_jobs=4,iid=False, cv=5)\n",
    "gsearch2.fit(train_hist_X,train_hist_y)\n",
    "print 'Best parameter set: ', gsearch2.best_params_\n",
    "print 'Best score: ', gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mean: 0.59317, std: 0.00503, params: {'n_estimators': 50, 'bootstrap': True, 'class_weight': 'balanced'}, mean: 0.59960, std: 0.00598, params: {'n_estimators': 100, 'bootstrap': True, 'class_weight': 'balanced'}, mean: 0.60071, std: 0.00660, params: {'n_estimators': 150, 'bootstrap': True, 'class_weight': 'balanced'}, mean: 0.60049, std: 0.00715, params: {'n_estimators': 200, 'bootstrap': True, 'class_weight': 'balanced'}, mean: 0.59094, std: 0.00509, params: {'n_estimators': 50, 'bootstrap': True, 'class_weight': 'balanced_subsample'}, mean: 0.59942, std: 0.00206, params: {'n_estimators': 100, 'bootstrap': True, 'class_weight': 'balanced_subsample'}, mean: 0.59991, std: 0.00472, params: {'n_estimators': 150, 'bootstrap': True, 'class_weight': 'balanced_subsample'}, mean: 0.60022, std: 0.00596, params: {'n_estimators': 200, 'bootstrap': True, 'class_weight': 'balanced_subsample'}, mean: 0.60259, std: 0.00461, params: {'n_estimators': 50, 'bootstrap': True, 'class_weight': None}, mean: 0.60857, std: 0.00455, params: {'n_estimators': 100, 'bootstrap': True, 'class_weight': None}, mean: 0.61375, std: 0.00742, params: {'n_estimators': 150, 'bootstrap': True, 'class_weight': None}, mean: 0.61451, std: 0.00826, params: {'n_estimators': 200, 'bootstrap': True, 'class_weight': None}, mean: 0.60339, std: 0.00764, params: {'n_estimators': 50, 'bootstrap': False, 'class_weight': 'balanced'}, mean: 0.60973, std: 0.00926, params: {'n_estimators': 100, 'bootstrap': False, 'class_weight': 'balanced'}, mean: 0.61437, std: 0.00742, params: {'n_estimators': 150, 'bootstrap': False, 'class_weight': 'balanced'}, mean: 0.61522, std: 0.00672, params: {'n_estimators': 200, 'bootstrap': False, 'class_weight': 'balanced'}, mean: 0.60339, std: 0.00764, params: {'n_estimators': 50, 'bootstrap': False, 'class_weight': 'balanced_subsample'}, mean: 0.60973, std: 0.00926, params: {'n_estimators': 100, 'bootstrap': False, 'class_weight': 'balanced_subsample'}, mean: 0.61437, std: 0.00742, params: {'n_estimators': 150, 'bootstrap': False, 'class_weight': 'balanced_subsample'}, mean: 0.61522, std: 0.00672, params: {'n_estimators': 200, 'bootstrap': False, 'class_weight': 'balanced_subsample'}, mean: 0.61777, std: 0.00772, params: {'n_estimators': 50, 'bootstrap': False, 'class_weight': None}, mean: 0.62687, std: 0.00941, params: {'n_estimators': 100, 'bootstrap': False, 'class_weight': None}, mean: 0.62777, std: 0.00830, params: {'n_estimators': 150, 'bootstrap': False, 'class_weight': None}, mean: 0.62902, std: 0.00759, params: {'n_estimators': 200, 'bootstrap': False, 'class_weight': None}]\n",
      "{'n_estimators': 200, 'bootstrap': False, 'class_weight': None}\n",
      "0.629016965967\n"
     ]
    }
   ],
   "source": [
    "# Pick n_estimators=80\n",
    "#Lets tune for max_depth and min_samples_split\n",
    "param_test = {'n_estimators':range(50,201,50), 'bootstrap':[True, False], \n",
    "              'class_weight':['balanced', 'balanced_subsample', None] }\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "gsearch2 = GridSearchCV(estimator = clf, param_grid = param_test, n_jobs=4,iid=False, cv=5)\n",
    "gsearch2.fit(train_X,train_y)\n",
    "print gsearch2.best_params_\n",
    "print gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I attempt to fit the data separately, with the two Random Forests with the best parameters. Apart from the score, we look at the classification report to see the errors so adjustments can be made accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (a random forest): 0.638958333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.69      0.72      3572\n",
      "          2       0.84      0.63      0.72      4276\n",
      "          3       0.26      0.65      0.37       409\n",
      "          4       0.33      0.53      0.41      1343\n",
      "\n",
      "avg / total       0.72      0.64      0.66      9600\n",
      "\n",
      "Accuracy (a random forest): 0.592291666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.45      0.42      0.44      3429\n",
      "          2       0.43      0.44      0.44      3124\n",
      "          3       0.93      0.91      0.92      1039\n",
      "          4       0.89      0.95      0.91      2008\n",
      "\n",
      "avg / total       0.59      0.59      0.59      9600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rfc2 = RandomForestClassifier(n_estimators=200, bootstrap=False, random_state=42)\n",
    "rfc2.fit(train_X, train_y)\n",
    "\n",
    "rfc5 = RandomForestClassifier(n_estimators=200, bootstrap=False, class_weight = 'balanced', random_state=42)\n",
    "rfc5.fit(train_hist_X, train_hist_y)\n",
    "\n",
    "print 'Accuracy (a random forest):', rfc2.score(valid_X, valid_y)\n",
    "print classification_report(rfc2.predict(valid_X),valid_y)\n",
    "\n",
    "print 'Accuracy (a random forest):', rfc5.score(valid_hist_X, valid_hist_y)\n",
    "print classification_report(rfc5.predict(valid_hist_X),valid_hist_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After trying the two random forest models individually, I noticed that the model on the pixel matrix classified classes 1 and 2 with good accuracy, while the model on the color histogram classified classes 3 and 4 with good accuracy. There is scope to combine the two models to create overall better classification.\n",
    "\n",
    "I split the training data in half, and train the two individual models on the first half of the train data. Then, I take the prediction probabilities of the models on the second half of the data, and train a new RandomForest Classifier. Then, we can look for this model's accuracy on the dev set. We also create a submission for the leaderboard, of predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All good  step 1\n",
      "All good  step 2\n",
      "Accuracy (random forest on pixels): 0.617767857143\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.66      0.70      4271\n",
      "          2       0.83      0.62      0.71      5031\n",
      "          3       0.22      0.57      0.32       463\n",
      "          4       0.30      0.52      0.38      1435\n",
      "\n",
      "avg / total       0.71      0.62      0.65     11200\n",
      "\n",
      "Accuracy (random forest on color histogram): 0.540535714286\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.46      0.42      0.44      4169\n",
      "          2       0.41      0.42      0.42      3679\n",
      "          3       0.88      0.79      0.83      1313\n",
      "          4       0.69      0.86      0.76      2039\n",
      "\n",
      "avg / total       0.54      0.54      0.54     11200\n",
      "\n",
      "Accuracy (combined random forest): 0.797708333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.80      0.79      3119\n",
      "          2       0.82      0.77      0.80      3438\n",
      "          3       0.86      0.85      0.85      1038\n",
      "          4       0.76      0.81      0.78      2005\n",
      "\n",
      "avg / total       0.80      0.80      0.80      9600\n",
      "\n",
      "Creating Submission\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Random Forest\n",
    "'''\n",
    "\n",
    "train_X_step1, train_X_step2, train_y_step1, train_y_step2 = train_test_split(train_X, train_y, test_size=0.5, random_state=42)\n",
    "train_hist_step1, train_hist_step2, train_yhist_step1, train_yhist_step2 = train_test_split(train_hist_X, train_hist_y, \n",
    "                                                                                            test_size=0.5, random_state=42)\n",
    "\n",
    "#checking that training sets are the same for both feature sets\n",
    "check = 'All good'\n",
    "for a, b in zip(train_y_step1, train_yhist_step1):\n",
    "    if a != b:\n",
    "        check = 'Not equal'\n",
    "print check, ' step 1'\n",
    "\n",
    "check = 'All good'\n",
    "for a, b in zip(train_y_step2, train_yhist_step2):\n",
    "    if a != b:\n",
    "        check = 'Not equal'\n",
    "print check, ' step 2'\n",
    "\n",
    "#Training 2 initial models\n",
    "rfc2 = RandomForestClassifier(n_estimators=200, bootstrap=False, random_state=42)\n",
    "rfc2.fit(train_X_step1, train_y_step1)\n",
    "\n",
    "rfc5 = RandomForestClassifier(n_estimators=200, bootstrap=False, class_weight = 'balanced', random_state=42)\n",
    "rfc5.fit(train_hist_step1, train_yhist_step1)\n",
    "\n",
    "print 'Accuracy (random forest on pixels):', rfc2.score(train_X_step2, train_y_step2)\n",
    "print classification_report(rfc2.predict(train_X_step2),train_y_step2)\n",
    "\n",
    "print 'Accuracy (random forest on color histogram):', rfc5.score(train_hist_step2, train_yhist_step2)\n",
    "print classification_report(rfc5.predict(train_hist_step2),train_yhist_step2)\n",
    "\n",
    "final_preds12_train = rfc2.predict_proba(train_X_step2)\n",
    "final_preds34_train = rfc5.predict_proba(train_hist_step2)\n",
    "\n",
    "final_preds12_valid = rfc2.predict_proba(valid_X)\n",
    "final_preds34_valid = rfc5.predict_proba(valid_hist_X)        \n",
    "\n",
    "#Creating training set for final model\n",
    "train_final = np.array([np.concatenate((final_preds12_train[i],final_preds34_train[i])) for i in range(len(final_preds12_train))])\n",
    "valid_final = np.array([np.concatenate((final_preds12_valid[i],final_preds34_valid[i])) for i in range(len(final_preds12_valid))])\n",
    "\n",
    "rfc6 = RandomForestClassifier(n_estimators=100, bootstrap=False)\n",
    "rfc6.fit(train_final, train_y_step2)\n",
    "fin_preds = rfc6.predict(valid_final)\n",
    "print 'Accuracy (combined random forest):', rfc6.score(valid_final, valid_y)\n",
    "print classification_report(fin_preds,valid_y)\n",
    "\n",
    "preds1 = rfc2.predict_proba(X_test)\n",
    "preds2 = rfc5.predict_proba(X_test_hist)\n",
    "\n",
    "test_final = np.array([np.concatenate((preds1[i], preds2[i])) for i in range(len(preds1))])\n",
    "preds_leaderboard = rfc6.predict(test_final)\n",
    "\n",
    "def create_submission(predictions, test_id):\n",
    "     with open('submit_rf6.csv', 'wb') as mycsvfile:\n",
    "            thedatawriter = csv.writer(mycsvfile)\n",
    "            thedatawriter.writerow(['Id','label'])\n",
    "            for pred,testid  in zip(predictions,test_id):\n",
    "                out = [testid,pred]\n",
    "                thedatawriter.writerow(out)\n",
    "    \n",
    "\n",
    "print('Creating Submission')\n",
    "create_submission(preds_leaderboard, X_test_id)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see above, that the combined model is able to achieve an accuracy of 80%.\n",
    "\n",
    "Below, we try and incorporate use of the unlabelled images to improve the classifiers by co-training. We train the first two classifiers as above. Then, we label the unlabelled images using the most confident prediction from the two classifiers. Once done, we re-train the original classifiers with the labelled examples and carry out the same exercise once again. Thus, the two models train each other with the labelled examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "Accuracy (a random forest new model pixels): 0.638958333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.69      0.72      3572\n",
      "          2       0.84      0.63      0.72      4276\n",
      "          3       0.26      0.65      0.37       409\n",
      "          4       0.33      0.53      0.41      1343\n",
      "\n",
      "avg / total       0.72      0.64      0.66      9600\n",
      "\n",
      "Accuracy (a random forest new model colors): 0.585729166667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.46      0.42      0.44      3543\n",
      "          2       0.41      0.44      0.42      3009\n",
      "          3       0.93      0.90      0.92      1049\n",
      "          4       0.87      0.94      0.91      1999\n",
      "\n",
      "avg / total       0.58      0.59      0.58      9600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Random Forest\n",
    "'''\n",
    "rfc1 = RandomForestClassifier(n_estimators=200, bootstrap=False, random_state=42)\n",
    "rfc1.fit(train_X, train_y)\n",
    "rfc3 = RandomForestClassifier(n_estimators=200, bootstrap=False, random_state=42)\n",
    "rfc3.fit(train_hist_X, train_hist_y)\n",
    "\n",
    "train_X_pixels = train_X\n",
    "train_X_colors = train_hist_X\n",
    "train_y_pixels = train_y\n",
    "train_y_colors = train_hist_y\n",
    "\n",
    "for i in range(100):\n",
    "    pred1 = rfc1.predict(np.array([X_unlabelled_pixels[i]]))\n",
    "    pred2 = rfc3.predict(np.array([X_unlabelled_colors[i]]))\n",
    "    \n",
    "    pred1_prob = rfc1.predict_proba(np.array([X_unlabelled_pixels[i]]))[0][int(pred1[0])-1]\n",
    "    pred2_prob = rfc3.predict_proba(np.array([X_unlabelled_colors[i]]))[0][int(pred2[0])-1]\n",
    "    \n",
    "    np.insert(train_X_pixels, len(train_X_pixels), X_unlabelled_pixels[i])\n",
    "    np.insert(train_X_colors, len(train_X_colors), X_unlabelled_colors[i])\n",
    "    if pred1_prob > pred2_prob:\n",
    "        np.insert(train_y_pixels, len(train_y_pixels), int(pred1[0]))\n",
    "        np.insert(train_y_colors, len(train_y_colors), int(pred1[0]))\n",
    "    else:\n",
    "        np.insert(train_y_pixels, len(train_y_pixels), int(pred2[0]))\n",
    "        np.insert(train_y_colors, len(train_y_colors), int(pred2[0]))\n",
    "    rfc1.fit(train_X_pixels, train_y_pixels)\n",
    "    rfc3.fit(train_X_colors, train_y_colors)\n",
    "\n",
    "print 'Accuracy (a random forest new model pixels):', rfc1.score(valid_X, valid_y)\n",
    "print classification_report(rfc1.predict(valid_X),valid_y)\n",
    "print 'Accuracy (a random forest new model colors):', rfc3.score(valid_hist_X, valid_hist_y)\n",
    "print classification_report(rfc3.predict(valid_hist_X),valid_hist_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
